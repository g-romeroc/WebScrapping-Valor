{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm #loop melhor \n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "\n",
    "# Wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando base de dados\n",
    "#%%time\n",
    "base = pd.read_csv('Valor_Scrap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Título</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-25 10:20:00</td>\n",
       "      <td>Focus: mercado aponta estabilidade em inflação...</td>\n",
       "      <td>SÃO PAULO - O mercado manteve a proj...</td>\n",
       "      <td>https://valor.globo.com/brasil/noticia/2011/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-25 10:30:00</td>\n",
       "      <td>Bolsas da Europa caem; dívida dos EUA e rating...</td>\n",
       "      <td>SÃO PAULO - Os investidores nas bols...</td>\n",
       "      <td>https://valor.globo.com/financas/noticia/2011/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-25 11:00:00</td>\n",
       "      <td>Seis meses depois, Furnas só trocou de presidente</td>\n",
       "      <td>SÃO PAULO - Símbolo das mudanças que...</td>\n",
       "      <td>https://valor.globo.com/politica/noticia/2011/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-07-25 11:10:00</td>\n",
       "      <td>Lupatech fecha contratos para plataformas de p...</td>\n",
       "      <td>SÃO PAULO - A Lupatech S.A, especial...</td>\n",
       "      <td>https://valor.globo.com/empresas/noticia/2011/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-25 14:04:00</td>\n",
       "      <td>Homem que confessou massacre na Noruega ficará...</td>\n",
       "      <td>ÃO PAULO – O juiz Kim Heger determin...</td>\n",
       "      <td>https://valor.globo.com/mundo/noticia/2011/07/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678611</th>\n",
       "      <td>2022-12-31 19:28:00</td>\n",
       "      <td>Cláudio Castro, que apoiou Bolsonaro, será o ú...</td>\n",
       "      <td>O governador do Rio, Cláudio Castro ...</td>\n",
       "      <td>https://valor.globo.com/politica/noticia/2022/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678612</th>\n",
       "      <td>2022-12-31 19:37:00</td>\n",
       "      <td>Lula ainda não decidiu sobre desfile em carro ...</td>\n",
       "      <td>Futuro ministro da Comunicação Socia...</td>\n",
       "      <td>https://valor.globo.com/politica/noticia/2022/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678613</th>\n",
       "      <td>2022-12-31 19:51:00</td>\n",
       "      <td>Lula conversa com autoridades da Ucrânia e Rús...</td>\n",
       "      <td>O presidente eleito Luiz Inácio Lula...</td>\n",
       "      <td>https://valor.globo.com/politica/noticia/2022/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678614</th>\n",
       "      <td>2022-12-31 20:23:00</td>\n",
       "      <td>MEC publica portaria regulamentando cursos de ...</td>\n",
       "      <td>O Ministério da Educação (MEC) acaba...</td>\n",
       "      <td>https://valor.globo.com/empresas/noticia/2022/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678615</th>\n",
       "      <td>2022-12-31 20:44:00</td>\n",
       "      <td>Em pronunciamento, Mourão não cita Bolsonaro e...</td>\n",
       "      <td>O vice-presidente, Hamilton Mourão (...</td>\n",
       "      <td>https://valor.globo.com/politica/noticia/2022/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678616 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Data  \\\n",
       "0       2011-07-25 10:20:00   \n",
       "1       2011-07-25 10:30:00   \n",
       "2       2011-07-25 11:00:00   \n",
       "3       2011-07-25 11:10:00   \n",
       "4       2011-07-25 14:04:00   \n",
       "...                     ...   \n",
       "678611  2022-12-31 19:28:00   \n",
       "678612  2022-12-31 19:37:00   \n",
       "678613  2022-12-31 19:51:00   \n",
       "678614  2022-12-31 20:23:00   \n",
       "678615  2022-12-31 20:44:00   \n",
       "\n",
       "                                                   Título  \\\n",
       "0       Focus: mercado aponta estabilidade em inflação...   \n",
       "1       Bolsas da Europa caem; dívida dos EUA e rating...   \n",
       "2       Seis meses depois, Furnas só trocou de presidente   \n",
       "3       Lupatech fecha contratos para plataformas de p...   \n",
       "4       Homem que confessou massacre na Noruega ficará...   \n",
       "...                                                   ...   \n",
       "678611  Cláudio Castro, que apoiou Bolsonaro, será o ú...   \n",
       "678612  Lula ainda não decidiu sobre desfile em carro ...   \n",
       "678613  Lula conversa com autoridades da Ucrânia e Rús...   \n",
       "678614  MEC publica portaria regulamentando cursos de ...   \n",
       "678615  Em pronunciamento, Mourão não cita Bolsonaro e...   \n",
       "\n",
       "                                                    Texto  \\\n",
       "0                 SÃO PAULO - O mercado manteve a proj...   \n",
       "1                 SÃO PAULO - Os investidores nas bols...   \n",
       "2                 SÃO PAULO - Símbolo das mudanças que...   \n",
       "3                 SÃO PAULO - A Lupatech S.A, especial...   \n",
       "4                 ÃO PAULO – O juiz Kim Heger determin...   \n",
       "...                                                   ...   \n",
       "678611            O governador do Rio, Cláudio Castro ...   \n",
       "678612            Futuro ministro da Comunicação Socia...   \n",
       "678613            O presidente eleito Luiz Inácio Lula...   \n",
       "678614            O Ministério da Educação (MEC) acaba...   \n",
       "678615            O vice-presidente, Hamilton Mourão (...   \n",
       "\n",
       "                                                      Url  \n",
       "0       https://valor.globo.com/brasil/noticia/2011/07...  \n",
       "1       https://valor.globo.com/financas/noticia/2011/...  \n",
       "2       https://valor.globo.com/politica/noticia/2011/...  \n",
       "3       https://valor.globo.com/empresas/noticia/2011/...  \n",
       "4       https://valor.globo.com/mundo/noticia/2011/07/...  \n",
       "...                                                   ...  \n",
       "678611  https://valor.globo.com/politica/noticia/2022/...  \n",
       "678612  https://valor.globo.com/politica/noticia/2022/...  \n",
       "678613  https://valor.globo.com/politica/noticia/2022/...  \n",
       "678614  https://valor.globo.com/empresas/noticia/2022/...  \n",
       "678615  https://valor.globo.com/politica/noticia/2022/...  \n",
       "\n",
       "[678616 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 1 - Realizando as modificações  \n",
    "#### 1) Tirar pontuações\n",
    "#### 2) Colocar tudo em letra minúscula \n",
    "#### 3) Retirar espaços duplos que vão aparecer após a retirada de pontuações\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Remover pontuações\n",
    "def remove_punct(text):\n",
    "    \"\"\"Remove pontuações do texto\"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "colunas = ['Título']\n",
    "for j in tqdm(colunas):\n",
    "    ## Colocando os textos em formato de string \n",
    "    base[f'{j}'] = base[f'{j}'].astype(str)\n",
    "    \n",
    "    ### Tirando as pontuações\n",
    "    ## Deleto as pontuações e colocamos '' no lugar - apagando as pontuações e criando uma nova coluna com o texto tratado\n",
    "    base[f'{j}'] = base[f'{j}'].map(lambda x: re.sub('[,\\.!?-]', ' ', x))\n",
    "    \n",
    "    # Colocando o texto em letras minúsculas\n",
    "    base[f'{j}'] = base[f'{j}'].map(lambda x: x.lower())\n",
    "    \n",
    "    # Remover pontuações + uma vez\n",
    "    base[f'{j}'] = base[f'{j}'].apply(remove_punct)\n",
    "    \n",
    "    # Tirando os espaços\n",
    "    base[f'{j}'] = base[f'{j}'].replace(r'\\s+', ' ', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 2 - Retirar Números e StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "### Retirando Números + Manter SP+RJ ###\n",
    "\n",
    "colunas = ['Título']\n",
    "for j in tqdm(colunas): \n",
    "    base[f'{j}'] = base[f'{j}'].replace(to_replace=r'\\d', value='', regex=True)\n",
    "    base[f'{j}'] = base[f'{j}'].str.replace('são paulo', 'são_paulo')\n",
    "    base[f'{j}'] = base[f'{j}'].str.replace('rio de janeiro', 'rio_de_janeiro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StopWords - Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gcard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('portuguese')\n",
    "stop_words.extend(['reuters','valor', 'foto', 'foto:', 'reprodução'])\n",
    "\n",
    "\n",
    "# Parte 1 - Retirando mais algumas palavras\n",
    "stop_words.extend(['de','a','o','que','e','do','da','em','um','para','e','com','nao','uma','os','no','se','na','por','mais','as','dos','como','mas','foi',\n",
    "                   'ao','ele','das','tem','a','seu','sua','ou','ser','quando','muito','ha','nos','ja','esta','eu','tambem','so','pelo','pela','ate','isso',\n",
    "                   'ela','entre','era','depois','sem','mesmo','aos','ter','seus','quem','nas','me','esse','eles','estao','voce','tinha','foram','essa','num',\n",
    "                   'nem','suas','meu','as','minha','tem','numa','pelos','elas','havia','seja','qual','sera','nos','tenho','lhe','deles','essas','esses','pelas',\n",
    "                   'este','fosse','dele','tu','te','voces','vos','lhes','meus','minhas','teu','tua','teus','tuas','nosso','nossa','nossos','nossas','dela','delas',\n",
    "                   'esta','estes','estas','aquele','aquela','aqueles','aquelas','isto','aquilo','estou','esta','estamos','estao','estive','esteve','estivemos',\n",
    "                   'estiveram','estava','estavamos','estavam','estivera','estiveramos','esteja','estejamos','estejam','estivesse','estivessemos','estivessem',\n",
    "                   'estiver','estivermos','estiverem','hei','ha','havemos','hao','houve','houvemos','houveram','houvera','houveramos','haja','hajamos','hajam',\n",
    "                   'houvesse','houvessemos','houvessem','houver','houvermos','houverem','houverei','houvera','houveremos','houverao','houveria','houveriamos',\n",
    "                   'houveriam','sou','somos','era','eramos','eram','fui','foi','fomos','foram','fora','foramos','seja','sejamos','sejam','fosse','fossemos',\n",
    "                   'fossem','for','formos','forem','serei','sera','seremos','serao','seria','seriamos','seriam','tenho','tem','temos','tem','tinha','tinhamos',\n",
    "                   'tinham','tive','teve','tivemos','tiveram','tivera','tiveramos','tenha','tenhamos','tenham','tivesse','tivessemos','tivessem','tiver','tivermos',\n",
    "                   'tiverem','terei','tera','teremos','terao','teria','teriamos','teriam'])\n",
    "\n",
    "# Parte 2 - Parte anterior com acento\n",
    "stop_words.extend(['de',  'a',  'o',  'que',  'e',  'do',  'da',  'em',  'um',  'para',  'é',  'com',  'não',  'uma',  'os',  'no',  'se',  'na',  'por',  'mais',  \n",
    "                    'as',  'dos',  'como',  'mas',  'foi',  'ao',  'ele',  'das',  'tem',  'à',  'seu',  'sua',  'ou',  'ser',  'quando',  'muito',  'há',  'nos',  \n",
    "                    'já',  'está',  'eu',  'também',  'só',  'pelo',  'pela',  'até',  'isso',  'ela',  'entre',  'era',  'depois',  'sem',  'mesmo',  'aos',  'ter', \n",
    "                    'seus',  'quem',  'nas',  'me',  'esse',  'eles',  'estão',  'você',  'tinha',  'foram',  'essa',  'num',  'nem',  'suas',  'meu',  'às',  'minha',\n",
    "                    'têm',  'numa',  'pelos',  'elas',  'havia',  'seja',  'qual',  'será',  'nós',  'tenho',  'lhe',  'deles',  'essas',  'esses',  'pelas',  'este',  \n",
    "                    'fosse',  'dele',  'tu',  'te',  'vocês',  'vos',  'lhes',  'meus',  'minhas',  'teu',  'tua',  'teus',  'tuas',  'nosso',  'nossa',  'nossos',  \n",
    "                    'nossas',  'dela',  'delas',  'esta',  'estes',  'estas',  'aquele',  'aquela',  'aqueles',  'aquelas',  'isto',  'aquilo',  'estou',  'está',  \n",
    "                    'estamos',  'estão',  'estive',  'esteve',  'estivemos',  'estiveram',  'estava',  'estávamos',  'estavam',  'estivera',  'estivéramos',  'esteja',  \n",
    "                    'estejamos',  'estejam',  'estivesse',  'estivéssemos',  'estivessem',  'estiver',  'estivermos',  'estiverem',  'hei',  'há',  'havemos',  'hão', \n",
    "                    'houve',  'houvemos',  'houveram',  'houvera',  'houvéramos',  'haja',  'hajamos',  'hajam',  'houvesse',  'houvéssemos',  'houvessem',  'houver',  \n",
    "                    'houvermos',  'houverem',  'houverei',  'houverá',  'houveremos',  'houverão',  'houveria',  'houveríamos',  'houveriam',  'sou',  'somos',  'são', \n",
    "                    'era',  'éramos',  'eram',  'fui',  'foi',  'fomos',  'foram',  'fora',  'fôramos',  'seja',  'sejamos',  'sejam',  'fosse',  'fôssemos',  'fossem', \n",
    "                    'for',  'formos',  'forem',  'serei',  'será',  'seremos',  'serão',  'seria',  'seríamos',  'seriam',  'tenho',  'tem',  'temos',  'tém',  'tinha',  \n",
    "                    'tínhamos',  'tinham',  'tive',  'teve',  'tivemos',  'tiveram',  'tivera',  'tivéramos',  'tenha',  'tenhamos',  'tenham',  'tivesse', \n",
    "                    'tivéssemos',  'tivessem',  'tiver',  'tivermos',  'tiverem',  'terei',  'terá',  'teremos',  'terão',  'teria',  'teríamos',  'teriam'])\n",
    "\n",
    "# Parte 2 - Adicionando mais um conjunto de palavras, porém essas palavras possuem acentos.\n",
    "\n",
    "const_words = [ 'a', 'à', 'adeus', 'agora', 'aí', 'ainda', 'além', 'algo', 'alguém', 'algum', 'alguma', 'algumas', 'alguns', 'ali', 'ampla', 'amplas', 'amplo', \n",
    "               'amplos', 'ano', 'anos', 'ante', 'antes', 'ao', 'aos', 'apenas', 'apoio', 'após', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aqui', 'aquilo', \n",
    "               'área', 'as', 'às', 'assim', 'até', 'atrás', 'através', 'baixo', 'bastante', 'bem', 'boa', 'boas', 'bom', 'bons', 'breve', 'cá', 'cada', 'catorze',\n",
    "               'cedo', 'cento', 'certamente', 'certeza', 'cima', 'cinco', 'coisa', 'coisas', 'com', 'como', 'conselho', 'contra', 'contudo', 'custa', 'da', 'dá',\n",
    "               'dão', 'daquela', 'daquelas', 'daquele', 'daqueles', 'dar', 'das', 'de', 'debaixo', 'dela', 'delas', 'dele', 'deles', 'demais', 'dentro', 'depois', \n",
    "               'desde', 'dessa', 'dessas', 'desse', 'desses', 'desta', 'destas', 'deste', 'destes', 'deve', 'devem', 'devendo', 'dever', 'deverá', 'deverão', 'deveria', \n",
    "               'deveriam', 'devia', 'deviam', 'dez', 'dezanove', 'dezasseis', 'dezassete', 'dezoito', 'dia', 'diante', 'disse', 'disso', 'disto', 'dito', 'diz', 'dizem', \n",
    "               'dizer', 'do', 'dois', 'dos', 'doze', 'duas', 'dúvida', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'embora', 'enquanto', 'entre', 'era', 'eram', 'éramos',\n",
    "               'és', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estás', 'estava', 'estavam', 'estávamos', 'este', 'esteja', \n",
    "               'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', \n",
    "               'estivessem', 'estivéssemos', 'estiveste', 'estivestes', 'estou', 'etc', 'eu', 'exemplo', 'faço', 'falta', 'favor', 'faz', 'fazeis', 'fazem', 'fazemos',\n",
    "               'fazendo', 'fazer', 'fazes', 'feita', 'feitas', 'feito', 'feitos', 'fez', 'fim', 'final', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', \n",
    "               'forma', 'formos', 'fosse', 'fossem', 'fôssemos', 'foste', 'fostes', 'fui', 'geral', 'grande', 'grandes', 'grupo', 'há', 'haja', 'hajam', 'hajamos', 'hão',\n",
    "               'havemos', 'havia', 'hei', 'hoje', 'hora', 'horas', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', \n",
    "               'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'la', 'lá', \n",
    "               'lado', 'lhe', 'lhes', 'lo', 'local', 'logo', 'longe', 'lugar', 'maior', 'maioria', 'mais', 'mal', 'mas', 'máximo', 'me', 'meio', 'menor', 'menos', 'mês',\n",
    "               'meses', 'mesma', 'mesmas', 'mesmo', 'mesmos', 'meu', 'meus', 'mil', 'minha', 'minhas', 'momento', 'muita', 'muitas', 'muito', 'muitos', 'na', 'nada', 'não', \n",
    "               'naquela', 'naquelas', 'naquele', 'naqueles', 'nas', 'nem', 'nenhum', 'nenhuma', 'nessa', 'nessas', 'nesse', 'nesses', 'nesta', 'nestas', 'neste', 'nestes', \n",
    "               'ninguém', 'nível', 'no', 'noite', 'nome', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'nova', 'novas', 'nove', 'novo', 'novos', 'num', 'numa', \n",
    "               'número', 'nunca', 'o', 'obra', 'obrigada', 'obrigado', 'oitava', 'oitavo', 'oito', 'onde', 'ontem', 'onze', 'os', 'ou', 'outra', 'outras', 'outro', 'outros', \n",
    "               'para', 'parece', 'parte', 'partir', 'paucas', 'pela', 'pelas', 'pelo', 'pelos', 'pequena', 'pequenas', 'pequeno', 'pequenos', 'per', 'perante', 'perto', \n",
    "               'pode', 'pude', 'pôde', 'podem', 'podendo', 'poder', 'poderia', 'poderiam', 'podia', 'podiam', 'põe', 'põem', 'pois', 'ponto', 'pontos', 'por', 'porém',\n",
    "               'porque', 'porquê', 'posição', 'possível', 'possivelmente', 'posso', 'pouca', 'poucas', 'pouco', 'poucos', 'primeira', 'primeiras', 'primeiro', 'primeiros',\n",
    "               'própria', 'próprias', 'próprio', 'próprios', 'próxima', 'próximas', 'próximo', 'próximos', 'pude', 'puderam', 'quais', 'quáis', 'qual', 'quando', 'quanto', \n",
    "               'quantos', 'quarta', 'quarto', 'quatro', 'que', 'quê', 'quem', 'quer', 'quereis', 'querem', 'queremas', 'queres', 'quero', 'questão', 'quinta', 'quinto',\n",
    "               'quinze', 'relação', 'sabe', 'sabem', 'se', 'segunda', 'segundo', 'sei', 'seis', 'seja', 'sejam', 'sejamos', 'sem', 'sempre', 'sendo', 'ser', 'será', \n",
    "               'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'sete', 'sétima', 'sétimo', 'seu', 'seus', 'sexta', 'sexto', 'si', 'sido', 'sim', 'sistema', \n",
    "               'só', 'sob', 'sobre', 'sois', 'somos', 'sou', 'sua', 'suas', 'tal', 'talvez', 'também', 'tampouco', 'tanta', 'tantas', 'tanto', 'tão', 'tarde', 'te', 'tem',\n",
    "               'tém', 'têm', ' só ', 'temos', 'tendes', 'tendo', 'tenha', 'tenham', 'tenhamos', 'tenho', 'tens', 'ter', 'terá', 'terão', 'terceira', 'terceiro', 'terei', 'teremos',\n",
    "               'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'ti', 'tido', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', \n",
    "               'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tiveste', 'tivestes', 'toda', 'todas', 'todavia', 'todo', 'todos', 'trabalho', 'três', 'treze', \n",
    "               'tu', 'tua', 'tuas', 'tudo', 'última', 'últimas', 'último', 'últimos', 'um', 'uma', 'umas', 'uns', 'vai', 'vais', 'vão', 'vários', 'vem', 'vêm', 'vendo',\n",
    "               'vens', 'ver', 'vez', 'vezes', 'viagem', 'vindo', 'vinte', 'vir', 'você', 'vocês', 'vos', 'vós', 'vossa', 'vossas', 'vosso', 'vossos', 'zero']\n",
    "stop_words.extend(const_words)\n",
    "\n",
    "# Parte 3 - Algumas outras\n",
    "stop_words.extend(['durante', 'pessoa', 'pergunte', 'perguntei', 'perguntando', 'pergunta','caso', 'sentido', 'deu', 'somente'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para remover palavras da lista\n",
    "def remove_words(text, remove_list):\n",
    "    return ' '.join([word for word in text.split() if word not in remove_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:13<00:00, 73.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Retirando as stopwords de cada uma das colunas\n",
    "colunas = ['Título']\n",
    "for j in tqdm(colunas): \n",
    "    base[f'{j}'] = base[f'{j}'].apply(lambda x: remove_words(x, stop_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StopWords - Parte 2\n",
    "\n",
    "Foi obersado que **143** notícias estão em inglês.\n",
    "\n",
    "*base[base['Texto'].str.startswith('the')]*\n",
    "\n",
    "Vamos utilizar uma pequena lista de stopwords em inglês, já que 143 é um número baixo.\n",
    "\n",
    "Fonte: Está nos comentários de https://gist.github.com/sebleier/554280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.77 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Outro conjunto de stopwords em pt-br\n",
    "stop_words2 = ['apesar', 'vamos']\n",
    "\n",
    "\n",
    "# StopWords em Inglês\n",
    "stop_words2.extend([\"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \n",
    "                    \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \n",
    "                    \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \n",
    "                    \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \n",
    "                    \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \n",
    "                    \"having\", \"do\", \"does\", \"did\", \"doing\", \"an\", \"the\", \"and\", \"but\", \"if\", \n",
    "                    \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \n",
    "                    \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \n",
    "                    \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \n",
    "                    \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n",
    "                    \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \n",
    "                    \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \n",
    "                    \"very\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"])\n",
    "\n",
    "\n",
    "# Retirando as stopwords2 de cada uma das colunas\n",
    "colunas = ['Título']\n",
    "for j in tqdm(colunas): \n",
    "    base[f'{j}'] = base[f'{j}'].apply(lambda x: remove_words(x, stop_words2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# Tirando os espaços duplos\n",
    "\n",
    "colunas = ['Título']\n",
    "for j in tqdm(colunas):      \n",
    "    base[f'{j}'] = base[f'{j}'].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remover palavras com 1 letra e outras pontuações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "def remove_one_letter_words(text):\n",
    "    return re.sub(r'\\b\\w{1}\\b', '', text)\n",
    "\n",
    "colunas = ['Título']\n",
    "for j in tqdm(colunas): \n",
    "    ## Retirando outras pontuações que ainda estavam no texto\n",
    "    base[f'{j}'] = base[f'{j}'].apply(lambda x: re.sub('[ºª°]', '', x))\n",
    "    ## Retirando palavras com uma letra\n",
    "    base[f'{j}'] = base[f'{j}'].apply(remove_one_letter_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Título</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-25 10:20:00</td>\n",
       "      <td>focus mercado aponta estabilidade inflação</td>\n",
       "      <td>SÃO PAULO - O mercado manteve a proj...</td>\n",
       "      <td>https://valor.globo.com/brasil/noticia/2011/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-25 10:30:00</td>\n",
       "      <td>bolsas europa caem dívida eua rating grécia pr...</td>\n",
       "      <td>SÃO PAULO - Os investidores nas bols...</td>\n",
       "      <td>https://valor.globo.com/financas/noticia/2011/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-25 11:00:00</td>\n",
       "      <td>furnas trocou presidente</td>\n",
       "      <td>SÃO PAULO - Símbolo das mudanças que...</td>\n",
       "      <td>https://valor.globo.com/politica/noticia/2011/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Data                                             Título  \\\n",
       "0  2011-07-25 10:20:00         focus mercado aponta estabilidade inflação   \n",
       "1  2011-07-25 10:30:00  bolsas europa caem dívida eua rating grécia pr...   \n",
       "2  2011-07-25 11:00:00                           furnas trocou presidente   \n",
       "\n",
       "                                               Texto  \\\n",
       "0            SÃO PAULO - O mercado manteve a proj...   \n",
       "1            SÃO PAULO - Os investidores nas bols...   \n",
       "2            SÃO PAULO - Símbolo das mudanças que...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://valor.globo.com/brasil/noticia/2011/07...  \n",
       "1  https://valor.globo.com/financas/noticia/2011/...  \n",
       "2  https://valor.globo.com/politica/noticia/2011/...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base com Título e Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.drop(['Texto', 'Url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Título</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-25 10:20:00</td>\n",
       "      <td>focus mercado aponta estabilidade inflação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-25 10:30:00</td>\n",
       "      <td>bolsas europa caem dívida eua rating grécia pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-25 11:00:00</td>\n",
       "      <td>furnas trocou presidente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-07-25 11:10:00</td>\n",
       "      <td>lupatech fecha contratos plataformas produção ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-25 14:04:00</td>\n",
       "      <td>homem confessou massacre noruega ficará detido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678611</th>\n",
       "      <td>2022-12-31 19:28:00</td>\n",
       "      <td>cláudio castro apoiou bolsonaro único governad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678612</th>\n",
       "      <td>2022-12-31 19:37:00</td>\n",
       "      <td>lula decidiu desfile carro aberto passagem fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678613</th>\n",
       "      <td>2022-12-31 19:51:00</td>\n",
       "      <td>lula conversa autoridades ucrânia rússia defen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678614</th>\n",
       "      <td>2022-12-31 20:23:00</td>\n",
       "      <td>mec publica portaria regulamentando cursos med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678615</th>\n",
       "      <td>2022-12-31 20:44:00</td>\n",
       "      <td>pronunciamento mourão cita bolsonaro crítica l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678616 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Data                                             Título\n",
       "0       2011-07-25 10:20:00         focus mercado aponta estabilidade inflação\n",
       "1       2011-07-25 10:30:00  bolsas europa caem dívida eua rating grécia pr...\n",
       "2       2011-07-25 11:00:00                           furnas trocou presidente\n",
       "3       2011-07-25 11:10:00  lupatech fecha contratos plataformas produção ...\n",
       "4       2011-07-25 14:04:00  homem confessou massacre noruega ficará detido...\n",
       "...                     ...                                                ...\n",
       "678611  2022-12-31 19:28:00  cláudio castro apoiou bolsonaro único governad...\n",
       "678612  2022-12-31 19:37:00  lula decidiu desfile carro aberto passagem fai...\n",
       "678613  2022-12-31 19:51:00  lula conversa autoridades ucrânia rússia defen...\n",
       "678614  2022-12-31 20:23:00  mec publica portaria regulamentando cursos med...\n",
       "678615  2022-12-31 20:44:00  pronunciamento mourão cita bolsonaro crítica l...\n",
       "\n",
       "[678616 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.to_csv('Base_Final_Título.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base com Data + Título e Primeiro Paragráfo da Notícia\n",
    "\n",
    "Neste ponto, unimos o título e o primeiro parágrafo de cada notícia em uma única seção para fácil referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar duas colunas \n",
    "base = base.assign(total=base['Título'].str.cat(base['pp'], sep=' '))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_total = base.loc[:, ['Data', 'total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_total.to_csv('Base_Final_PP.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
